C:\Users\rahul\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\utils\hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
`torch_dtype` is deprecated! Use `dtype` instead!
Some parameters are on the meta device because they were offloaded to the cpu and disk.
Initializing LLM Loader...
LOADING MODEL: Qwen/Qwen2.5-Coder-1.5B-Instruct
DEVICE MAP: auto
No GPU detected, using CPU
Found HuggingFace token (length: 37)
HuggingFace authentication successful
Loading tokenizer...
Loading model (this may take a while)...
MODEL DEVICE: cpu
Model loaded successfully

Generatin response for prompt: 'what is stack'
STREAM OUTPUT: GENERATION CONFIG: temp=0.4, top_p=0.9, rep_pen=1.1, no_repeat_ngram_size=2, max_tokens=256
A stack is a linear data structure that follows the Last In First Out (LIFO) principle. This means that the last element added to the stack will be the first one to be removed. Stacks are commonly used in various applications such as function calls in programming, undo/redo operations, implementing backtracking algorithms, etc.

forrtl: error (200): program aborting due to window-CLOSE event
Image              PC                Routine            Line        Source             
KERNELBASE.dll     00007FFD6F84B99D  Unknown               Unknown  Unknown
KERNEL32.DLL       00007FFD7166E8D7  Unknown               Unknown  Unknown
ntdll.dll          00007FFD7214C53C  Unknown               Unknown  Unknown
